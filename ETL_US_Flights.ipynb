{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "US Flights Data Engineering (ETL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import petl as etl\n",
    "import psycopg2 \n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hostname = 'i.rds.amazonaws.com'\n",
    "database = 'tests_data_engineering'\n",
    "username = ''\n",
    "pwd = ''\n",
    "port_id = 5432\n",
    "conn = None\n",
    "\n",
    "driver_ps = \"postgresql+psycopg2\"\n",
    "engine_str = \"{}://{}:{}@{}/{}\".format(driver_ps,username, pwd, hostname, database)\n",
    "\n",
    "schema_string = \"\"\n",
    "staging_table_name = \"staging_us_flights\"\n",
    "\n",
    "data_type_replace = {\n",
    "    'object'        :   'varchar',\n",
    "    'float64'       :   'float',\n",
    "    'int64'         :   'int',\n",
    "    'datetime64'    :   'datetime'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Postgres DB Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_db_connection():\n",
    "    \n",
    "    connection = psycopg2.connect(\n",
    "    host = hostname,\n",
    "    dbname = database,\n",
    "    user = username,\n",
    "    password = pwd,\n",
    "    port = port_id\n",
    "    )\n",
    "    \n",
    "    return connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions : ALTER Data Type & Primary Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alter_primarykey(table, column):\n",
    "    alter_pkey = '''ALTER TABLE {}.\"{}\" \n",
    "    ADD PRIMARY KEY (\"{}\") '''.format(schema_string,table, column )\n",
    "    cursor.execute(alter_pkey)\n",
    "    conn.commit()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alter_datatype(table, column, type):\n",
    "    alter_dtype = '''ALTER TABLE {}.\"{}\" \n",
    "    ALTER COLUMN \"{}\" TYPE {} '''.format(schema_string,table, column, type )\n",
    "    cursor.execute(alter_dtype)\n",
    "    conn.commit()\n",
    "    # USING \"{}\"::{} column,  type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function Date Dimension Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_dimension(date_df):\n",
    "    \n",
    "    date_df['YEAR'], date_df['QUARTER'] =  date_df['FLIGHTDATE'].dt.year, date_df['FLIGHTDATE'].dt.quarter\n",
    "    date_df['MONTH'], date_df['MONTHNAME'] =  date_df['FLIGHTDATE'].dt.month, date_df['FLIGHTDATE'].dt.month_name()\n",
    "    date_df['DAYSINMONTH'] =  date_df['FLIGHTDATE'].dt.days_in_month\n",
    "    date_df['WEEK'], date_df['WEEKDAY'] =  date_df['FLIGHTDATE'].dt.week, date_df['FLIGHTDATE'].dt.day_name()\n",
    "    date_df['DAY'], date_df['YEARDAY'] =  date_df['FLIGHTDATE'].dt.day, date_df['FLIGHTDATE'].dt.dayofyear\n",
    "    return date_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function Distance Bucket\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance_group( distance):\n",
    "    bucket = distance // 100\n",
    "    upper = (bucket + 1 ) * 100\n",
    "    lower = 0\n",
    "    if(bucket > 0):\n",
    "        lower = (100 * bucket ) + 1\n",
    "\n",
    "    return \"{}-{} miles\".format(lower, upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions : Staging Table Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_staging_table(cursor):\n",
    "    \n",
    "    # Read Source Text file to get columns and their types\n",
    "    #flight_table = etl.fromcsv('flights.txt',delimiter='|')\n",
    "    df = pd.read_csv('flights.txt', sep='|')\n",
    "    # df.head()\n",
    "    # df.dtypes\n",
    "    \n",
    "    column_string = \" ,\".join(\"{} {}\".format(name,desc) for (name,desc) in zip(df.columns, df.dtypes.replace(data_type_replace)))\n",
    "   \n",
    "    cursor.execute(\"DROP TABLE IF EXISTS {}.{}\".format(schema_string, staging_table_name))\n",
    "\n",
    "    cursor.execute( \"CREATE TABLE {}.{} ({})\".format(schema_string, staging_table_name, column_string))\n",
    "  \n",
    "    \n",
    "    flight_table = etl.fromcsv('flights.txt',delimiter='|')\n",
    "\n",
    "    flights_file = open('flights.txt')\n",
    "\n",
    "    copy_todb_sql = \"\"\"\n",
    "    COPY candidate6421.staging_us_flights FROM STDIN WITH\n",
    "        CSV\n",
    "        HEADER\n",
    "        DELIMITER AS '|'\n",
    "    \"\"\"\n",
    "    cursor.copy_expert(sql=copy_todb_sql, file=flights_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connection Init - psycopg2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = initialize_db_connection()\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "##Staging table creation\n",
    "# create_staging_table(cursor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Sql alchemy engine : Source file read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_engine' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/Amandeep/VS Projects/InterWorks/ETL_US_Flights.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/Amandeep/VS%20Projects/InterWorks/ETL_US_Flights.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m engine \u001b[39m=\u001b[39m create_engine(engine_str)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Amandeep/VS%20Projects/InterWorks/ETL_US_Flights.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m flights_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mflights.txt\u001b[39m\u001b[39m'\u001b[39m, sep\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m|\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'create_engine' is not defined"
     ]
    }
   ],
   "source": [
    "engine = create_engine(engine_str)\n",
    "flights_df = pd.read_csv('flights.txt', sep='|')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Airline Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_name = \"DIM_AIRLINE\"\n",
    "airline_df = pd.DataFrame(flights_df, columns=['AIRLINECODE', 'AIRLINENAME']).drop_duplicates()\n",
    "airline_df[\"AIRLINENAME\"] = airline_df[\"AIRLINENAME\"].str.split(\":\", 1).str[0] #.str.split(\"(\", 1, expand=True)[0]\n",
    "\n",
    "#write to sql\n",
    "# airline_df.to_sql(dim_name, engine, schema= schema_string, if_exists=\"replace\", index=False)\n",
    "\n",
    "airline_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dim_name = \"DIM_AIRLINE\"\n",
    "# alter_datatype( dim_name, \"AIRLINECODE\", \"CHAR(2)\")\n",
    "# alter_datatype( dim_name, \"AIRLINENAME\", \"VARCHAR(100)\")\n",
    "# alter_primarykey(dim_name, \"AIRLINECODE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Origin Airport Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/Amandeep/VS Projects/InterWorks/ETL_US_Flights.ipynb Cell 25\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Amandeep/VS%20Projects/InterWorks/ETL_US_Flights.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m dim_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mDIM_ORIGINAIRPORT\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/Amandeep/VS%20Projects/InterWorks/ETL_US_Flights.ipynb#X33sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m origin_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(flights_df, columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mORIGINAIRPORTCODE\u001b[39m\u001b[39m'\u001b[39m, \\\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Amandeep/VS%20Projects/InterWorks/ETL_US_Flights.ipynb#X33sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                                               \u001b[39m'\u001b[39m\u001b[39mORIGAIRPORTNAME\u001b[39m\u001b[39m'\u001b[39m,\\\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Amandeep/VS%20Projects/InterWorks/ETL_US_Flights.ipynb#X33sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                                               \u001b[39m'\u001b[39m\u001b[39mORIGINCITYNAME\u001b[39m\u001b[39m'\u001b[39m, \\\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Amandeep/VS%20Projects/InterWorks/ETL_US_Flights.ipynb#X33sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                                               \u001b[39m'\u001b[39m\u001b[39mORIGINSTATE\u001b[39m\u001b[39m'\u001b[39m, \\\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Amandeep/VS%20Projects/InterWorks/ETL_US_Flights.ipynb#X33sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                                               \u001b[39m'\u001b[39m\u001b[39mORIGINSTATENAME\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m.\u001b[39mdrop_duplicates()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Amandeep/VS%20Projects/InterWorks/ETL_US_Flights.ipynb#X33sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m#Clean ORIGAIRPORTNAME\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Amandeep/VS%20Projects/InterWorks/ETL_US_Flights.ipynb#X33sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m name\u001b[39m=\u001b[39m origin_df[\u001b[39m\"\u001b[39m\u001b[39mORIGAIRPORTNAME\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "dim_name = \"DIM_ORIGINAIRPORT\"\n",
    "origin_df = pd.DataFrame(flights_df, columns=['ORIGINAIRPORTCODE', \\\n",
    "                                              'ORIGAIRPORTNAME',\\\n",
    "                                              'ORIGINCITYNAME', \\\n",
    "                                              'ORIGINSTATE', \\\n",
    "                                              'ORIGINSTATENAME']).drop_duplicates()\n",
    "\n",
    "#Clean ORIGAIRPORTNAME\n",
    "name= origin_df[\"ORIGAIRPORTNAME\"].str.split(\":\", 1)\n",
    "\n",
    "origin_df[\"ORIGAIRPORTNAME\"] = name.str[1].str.strip()\n",
    "\n",
    "#Extract State from airportName, if null\n",
    "origin_df[\"ORIGINSTATE\"] = origin_df[\"ORIGINSTATE\"].fillna(name.str[0].str[-2:])\n",
    "\n",
    "#Clean ORIGINCITYNAME\n",
    "origin_df[\"ORIGINCITYNAME\"] = origin_df[\"ORIGINCITYNAME\"].str.split(\"/\", 1).str[0] \n",
    "\n",
    "\n",
    "#write to sql\n",
    "# origin_df.sort_values(by=['ORIGINAIRPORTCODE']).to_sql(dim_name, engine, schema= schema_string, if_exists=\"replace\", index=False)\n",
    "\n",
    "origin_df.loc[origin_df[\"ORIGINSTATENAME\"] == 'nan'].head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dim_name = \"DIM_ORIGINAIRPORT\"\n",
    "\n",
    "# alter_datatype( dim_name, \"ORIGINAIRPORTCODE\", \"CHAR(3)\")\n",
    "# alter_primarykey(dim_name, \"ORIGINAIRPORTCODE\")\n",
    "# alter_datatype( dim_name, \"ORIGAIRPORTNAME\", \"VARCHAR(150)\")\n",
    "# alter_datatype( dim_name, \"ORIGINCITYNAME\", \"VARCHAR(50)\")\n",
    "# alter_datatype( dim_name, \"ORIGINSTATE\", \"CHAR(2)\")\n",
    "# alter_datatype( dim_name, \"ORIGINSTATENAME\", \"VARCHAR(50)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Destination Airport Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_name = \"DIM_DESTAIRPORT\"\n",
    "dest_df = pd.DataFrame(flights_df, columns=['DESTAIRPORTCODE', \\\n",
    "                                              'DESTAIRPORTNAME',\\\n",
    "                                              'DESTCITYNAME', \\\n",
    "                                              'DESTSTATE', \\\n",
    "                                              'DESTSTATENAME']).drop_duplicates()\n",
    "\n",
    "#Clean ORIGAIRPORTNAME\n",
    "name= dest_df[\"DESTAIRPORTNAME\"].str.split(\":\", 1)\n",
    "\n",
    "dest_df[\"DESTAIRPORTNAME\"] = name.str[1].str.strip()\n",
    "\n",
    "#Extract State from airportName, if null\n",
    "dest_df[\"DESTSTATE\"] = dest_df[\"DESTSTATE\"].fillna(name.str[0].str[-2:])\n",
    "\n",
    "#Clean CITYNAME : Save multi cities values to new columns\n",
    "dest_df[[\"DESTCITYNAME\", \"DESTCITY1\", \"DESTCITY2\"]] = dest_df[\"DESTCITYNAME\"].str.split(\"/\", expand=True)\n",
    "\n",
    "#write to sql\n",
    "# dest_df.sort_values(by=['DESTAIRPORTCODE']).to_sql(dim_name, engine, schema= schema_string, if_exists=\"replace\", index=False)\n",
    "\n",
    "# dest_df.loc[dest_df[\"DESTSTATE\"] == 'PA'].head()\n",
    "dest_df.loc[dest_df[\"DESTAIRPORTNAME\"]  == 'nan'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# dim_name = \"DIM_DESTAIRPORT\"\n",
    "\n",
    "# # alter_datatype( dim_name, \"DESTAIRPORTCODE\", \"CHAR(3)\")\n",
    "# # alter_primarykey(dim_name, \"DESTAIRPORTCODE\")\n",
    "# alter_datatype( dim_name, \"DESTAIRPORTNAME\", \"VARCHAR(150)\")\n",
    "# alter_datatype( dim_name, \"DESTCITYNAME\", \"VARCHAR(50)\")\n",
    "# alter_datatype( dim_name, \"DESTSTATE\", \"CHAR(2)\")\n",
    "# alter_datatype( dim_name, \"DESTSTATENAME\", \"VARCHAR(50)\")\n",
    "# alter_datatype( dim_name, \"DESTCITY1\", \"VARCHAR(50)\")\n",
    "# alter_datatype( dim_name, \"DESTCITY2\", \"VARCHAR(50)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Date Dimension Derivation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_name = \"DIM_DATE\"\n",
    "date_df = pd.DataFrame(flights_df, columns=['FLIGHTDATE']).drop_duplicates()\n",
    "\n",
    "#convert number to string to date\n",
    "date_df['FLIGHTDATE'] = pd.to_datetime(date_df[\"FLIGHTDATE\"].astype(str))\n",
    "\n",
    "#create date parts\n",
    "date_df = get_date_dimension(date_df)\n",
    "\n",
    "#write to SQL\n",
    "# date_df.sort_values(by=['FLIGHTDATE']).to_sql(dim_name, engine, schema= schema_string, if_exists=\"replace\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# dim_name = \"DIM_DATE\"\n",
    "\n",
    "# alter_datatype( dim_name, \"FLIGHTDATE\", \"DATE\")\n",
    "# alter_primarykey(dim_name, \"FLIGHTDATE\")\n",
    "# alter_datatype( dim_name, \"YEAR\", \"SMALLINT\")\n",
    "# alter_datatype( dim_name, \"QUARTER\", \"SMALLINT\")\n",
    "# alter_datatype( dim_name, \"MONTH\", \"SMALLINT\")\n",
    "# alter_datatype( dim_name, \"MONTHNAME\", \"VARCHAR(10)\")\n",
    "# alter_datatype( dim_name, \"DAYSINMONTH\", \"SMALLINT\")\n",
    "# alter_datatype( dim_name, \"WEEK\", \"SMALLINT\")\n",
    "# alter_datatype( dim_name, \"WEEKDAY\", \"VARCHAR(10)\")\n",
    "# alter_datatype( dim_name, \"DAY\", \"SMALLINT\")\n",
    "# alter_datatype( dim_name, \"YEARDAY\", \"SMALLINT\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flight Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_name = \"DIM_FLIGHT\"\n",
    "\n",
    "dflight_df = pd.DataFrame(flights_df, columns=['TRANSACTIONID', 'FLIGHTDATE','TAILNUM','FLIGHTNUM',\t'DEPTIME','DEPDELAY', \\\n",
    "                                                'TAXIOUT','TAXIIN',\t'ARRTIME',\t'ARRDELAY',\t'DISTANCE'])\n",
    "\n",
    "#convert number to string to date\n",
    "dflight_df['FLIGHTDATE'] = pd.to_datetime(dflight_df[\"FLIGHTDATE\"].astype(str))\n",
    "\n",
    "\n",
    "#convert number to time for DEPTIME and ARRTIME\n",
    "deptime = dflight_df[\"DEPTIME\"].astype(str).str.replace(\"\\.0\", \"\", regex=True).str.zfill(4)\n",
    "deptime = deptime.str.replace(\"0nan\", \"\", regex=True)\n",
    "dflight_df['DEPTIME'] = pd.to_datetime( deptime, format='%H%M',  errors='coerce').dt.time\n",
    "\n",
    "arrtime = dflight_df[\"ARRTIME\"].astype(str).str.replace(\"\\.0\", \"\", regex=True).str.zfill(4)\n",
    "arrtime = arrtime.str.replace(\"0nan\", \"\", regex=True)\n",
    "dflight_df['ARRTIME'] = pd.to_datetime( arrtime, format='%H%M',  errors='coerce').dt.time\n",
    "\n",
    "# DEPDELAY, ARRDELAY, TAXIIN, TAXIOUT to integer\n",
    "\n",
    "cols_to_numeric = [\"DEPDELAY\", \"ARRDELAY\", \"TAXIOUT\", \"TAXIIN\"]\n",
    "dflight_df[cols_to_numeric] =  dflight_df[cols_to_numeric].fillna(0).astype(int)\n",
    "\n",
    "#Distance to int\n",
    "dflight_df[\"DISTANCE\"]  = dflight_df[\"DISTANCE\"].str.split().str[0].fillna(0).astype(int)\n",
    "\n",
    "#TAILNUM \n",
    "dflight_df[\"TAILNUM\"]  = dflight_df[\"TAILNUM\"].fillna('N/A')\n",
    "\n",
    "\n",
    "\n",
    "#write to SQL\n",
    "# dflight_df.sort_values(by=['FLIGHTDATE']).to_sql(dim_name, engine, schema= schema_string, if_exists=\"replace\", index=False)\n",
    "\n",
    "# dflight_df.sort_values(by=['FLIGHTDATE']).head(20)\n",
    "dflight_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dim_name = \"DIM_FLIGHT\"\n",
    "\n",
    "# alter_datatype( dim_name, \"TRANSACTIONID\", \"BIGINT\")\n",
    "# alter_primarykey(dim_name, \"TRANSACTIONID\")\n",
    "# alter_datatype( dim_name, \"FLIGHTDATE\", \"DATE\")\n",
    "# alter_datatype( dim_name, \"TAILNUM\", \"CHAR(6)\")\n",
    "# alter_datatype( dim_name, \"FLIGHTNUM\", \"SMALLINT\") --change it to CHAR(4)\n",
    "# alter_datatype( dim_name, \"DEPTIME\", \"TIME\")\n",
    "# alter_datatype( dim_name, \"ARRTIME\", \"TIME\")\n",
    "# alter_datatype( dim_name, \"DEPDELAY\", \"SMALLINT\")\n",
    "# alter_datatype( dim_name, \"TAXIOUT\", \"SMALLINT\")\n",
    "# alter_datatype( dim_name, \"TAXIIN\", \"SMALLINT\")\n",
    "# alter_datatype( dim_name, \"ARRDELAY\", \"SMALLINT\")\n",
    "# alter_datatype( dim_name, \"DISTANCE\", \"SMALLINT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FACT FLIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fact_table = \"FACT_FLIGHTS\"\n",
    "\n",
    "fact_df = pd.DataFrame(flights_df, columns=['TRANSACTIONID', 'FLIGHTDATE','DEPTIME','DEPDELAY', \\\n",
    "                                                \"AIRLINECODE\", 'ORIGINAIRPORTCODE', 'DESTAIRPORTCODE',\\\n",
    "                                                'ARRTIME',\t'ARRDELAY',\t'DISTANCE', 'CANCELLED', 'DIVERTED'])\n",
    "\n",
    "\n",
    "#FACT Flight ID - AUTO Increment\n",
    "fact_df.insert(0, 'FACTFLIGHTID', range(1, 1 + len(fact_df)))\n",
    "\n",
    "#CANCELLED to bool\n",
    "fact_df[ \"CANCELLED\"] = fact_df[ \"CANCELLED\"].map({'F': False,'0': False, 'False' :False, \\\n",
    "                                                'T': True, 'True': True, '1': True})\n",
    "#Diverted to bool \n",
    "fact_df[\"DIVERTED\"] = fact_df[\"DIVERTED\"].map({'F': False,'0': False, 'False' :False, \\\n",
    "                                                'T': True, 'True': True, '1': True})\n",
    "#convert number to string to date\n",
    "fact_df['FLIGHTDATE'] = pd.to_datetime(fact_df[\"FLIGHTDATE\"].astype(str))\n",
    "\n",
    "\n",
    "#convert number to time for DEPTIME and ARRTIME\n",
    "deptime = fact_df[\"DEPTIME\"].astype(str).str.replace(\"\\.0\", \"\", regex=True).str.zfill(4)\n",
    "deptime = deptime.str.replace(\"0nan\", \"\", regex=True)\n",
    "fact_df['DEPTIME'] = pd.to_datetime( deptime, format='%H%M',  errors='coerce')\n",
    "\n",
    "arrtime = fact_df[\"ARRTIME\"].astype(str).str.replace(\"\\.0\", \"\", regex=True).str.zfill(4)\n",
    "arrtime = arrtime.str.replace(\"0nan\", \"\", regex=True)\n",
    "fact_df['ARRTIME'] = pd.to_datetime( arrtime, format='%H%M',  errors='coerce')\n",
    "\n",
    "# DEPDELAY, ARRDELAY, TAXIIN, TAXIOUT to integer\n",
    "\n",
    "cols_to_numeric = [\"DEPDELAY\", \"ARRDELAY\"]\n",
    "fact_df[cols_to_numeric] =  fact_df[cols_to_numeric].fillna(0).astype(int)\n",
    "\n",
    "#Distance to int\n",
    "fact_df[\"DISTANCE\"]  = fact_df[\"DISTANCE\"].str.split().str[0].fillna(0).astype(int)\n",
    "\n",
    "#Dep Delay > 15\n",
    "fact_df[\"DEPDELAYGT15\"] = np.where(fact_df[\"DEPDELAY\"] > 15, 1, 0)\n",
    "\n",
    "#Distance Group\n",
    "fact_df[\"DISTANCEGROUP\"] = fact_df.apply(lambda x: get_distance_group(x.DISTANCE), axis=1)\n",
    "\n",
    "#ElapsedTime\n",
    "elapsedtime =  fact_df[\"ARRTIME\"] - fact_df[\"DEPTIME\"] \n",
    "fact_df[\"ACTUALELAPSEDTIME\"]  = elapsedtime.dt.total_seconds() / 60\n",
    "fact_df[\"ACTUALELAPSEDTIME\"] = np.where( fact_df[ \"CANCELLED\"] , 0, fact_df[\"ACTUALELAPSEDTIME\"].fillna(0).astype(int))\n",
    "\n",
    "#NEXTDAYARR\n",
    "fact_df[\"NEXTDAYARR\"] = np.where(  ( fact_df[\"ACTUALELAPSEDTIME\"] + fact_df[\"ARRDELAY\"] - fact_df[\"DEPDELAY\"] > 1440) | (fact_df[\"ACTUALELAPSEDTIME\"] < 0 )   , 1, 0)\n",
    "\n",
    "# fact_df[\"ACTUALELAPSEDTIME\"] = np.where( fact_df[\"ACTUALELAPSEDTIME\"] < 0, 1440 +fact_df[\"ACTUALELAPSEDTIME\"] , fact_df[\"ACTUALELAPSEDTIME\"] )\n",
    "# fact_df.loc[fact_df[\"NEXTDAYARR\"]  == 1]\n",
    "\n",
    "cols_to_drop = ['DEPTIME','DEPDELAY', 'ARRTIME', 'DISTANCE',\t'ARRDELAY', 'ACTUALELAPSEDTIME']\n",
    "fact_df.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "#write to SQL\n",
    "# fact_df.sort_values(by=['TRANSACTIONID']).to_sql(fact_table, engine, schema= schema_string, if_exists=\"replace\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_df.loc[(fact_df[\"ACTUALELAPSEDTIME\"] > -100) & (fact_df[\"NEXTDAYARR\"]  == 1) ].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = initialize_db_connection()\n",
    "\n",
    "cursor = conn.cursor()\n",
    "fact_table = \"FACT_FLIGHTS\"\n",
    "\n",
    "# alter_primarykey(fact_table, \"FACTFLIGHTID\")\n",
    "# alter_datatype( fact_table, \"TRANSACTIONID\", \"BIGINT\")\n",
    "# alter_datatype( fact_table, \"FLIGHTDATE\", \"DATE\")\n",
    "# alter_datatype( fact_table, \"AIRLINECODE\", \"CHAR(2)\")\n",
    "# alter_datatype( fact_table, \"ORIGINAIRPORTCODE\", \"CHAR(3)\")\n",
    "# alter_datatype( fact_table, \"DESTAIRPORTCODE\", \"CHAR(3)\")\n",
    "# alter_datatype( fact_table, \"CANCELLED\", \"BOOLEAN\")\n",
    "# alter_datatype( fact_table, \"DIVERTED\", \"BOOLEAN\")\n",
    "# alter_datatype( fact_table, \"DEPDELAYGT15\", \"BIT(1)\")\n",
    "# alter_datatype( fact_table, \"DISTANCEGROUP\", \"VARCHAR(30)\")\n",
    "# alter_datatype( fact_table, \"NEXTDAYARR\", \"BIT(1)\")\n",
    "\n",
    "# \"TRANSACTIONID\", \"FLIGHTDATE\", \"AIRLINECODE\", \"ORIGINAIRPORTCODE\", \"DESTAIRPORTCODE\", \n",
    "# \"CANCELLED\", \"DIVERTED\", \"DEPDELAYGT15\", \"DISTANCEGROUP\", \"NEXTDAYARR\"\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conn.commit()\n",
    "cursor.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
